"""
Há»‡ thá»‘ng kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c cá»§a thuáº­t toÃ¡n phÃ¢n loáº¡i sinh viÃªn
Sá»­ dá»¥ng K-means + KNN + PhÃ¡t hiá»‡n báº¥t thÆ°á»ng
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.metrics import confusion_matrix, classification_report
from datetime import datetime
import json
import os

from data_generator import StudentDataGenerator
from student_classifier import StudentClassifier
from skill_evaluator import SkillEvaluator


class ClassifierValidator:
    """Kiá»ƒm tra Ä‘á»™ chÃ­nh xÃ¡c cá»§a há»‡ thá»‘ng phÃ¢n loáº¡i sinh viÃªn"""
    
    def __init__(self):
        self.results = {}
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def load_data(self):
        """Load dá»¯ liá»‡u sinh viÃªn tá»« Supabase"""
        print("ğŸ“Š Äang táº£i dá»¯ liá»‡u tá»« Supabase...")
        generator = StudentDataGenerator(
            seed=42, 
            use_supabase=True  # DÃ¹ng Supabase
        )
        students = generator.load_all_students()
        print(f"   âœ… ÄÃ£ táº£i {len(students)} sinh viÃªn tá»« Supabase")
        return students
    
    def evaluate_skills(self, students):
        """ÄÃ¡nh giÃ¡ ká»¹ nÄƒng cho táº¥t cáº£ sinh viÃªn"""
        print("ğŸ” Äang Ä‘Ã¡nh giÃ¡ ká»¹ nÄƒng...")
        skill_evaluator = SkillEvaluator()
        for student in students:
            skill_evaluations = skill_evaluator.evaluate_all_courses(student)
            student["skill_evaluations"] = skill_evaluations
        print(f"   âœ… ÄÃ£ Ä‘Ã¡nh giÃ¡ ká»¹ nÄƒng cho {len(students)} sinh viÃªn")
        return students
    
    def run_classification(self, students, normalization_method='minmax'):
        """Cháº¡y phÃ¢n loáº¡i vá»›i K-means + KNN"""
        print(f"ğŸ¤– Äang phÃ¢n loáº¡i (chuáº©n hÃ³a: {normalization_method})...")
        classifier = StudentClassifier(n_clusters=4, normalization_method=normalization_method)
        classifier.fit(students)
        classified = classifier.predict(students)
        print(f"   âœ… ÄÃ£ phÃ¢n loáº¡i {len(classified)} sinh viÃªn")
        return classified, classifier
    
    def calculate_metrics(self, classified_students):
        """TÃ­nh cÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡"""
        # Láº¥y labels
        levels = [s.get('final_level', 'Unknown') for s in classified_students]
        kmeans_pred = [s.get('kmeans_prediction', 'Unknown') for s in classified_students]
        knn_pred = [s.get('knn_prediction', 'Unknown') for s in classified_students]
        
        # Äáº¿m phÃ¢n bá»‘
        level_counts = {}
        for level in levels:
            level_counts[level] = level_counts.get(level, 0) + 1
        
        # Äáº¿m báº¥t thÆ°á»ng
        anomaly_count = sum(1 for s in classified_students if s.get('anomaly_detected', False))
        
        # TÃ­nh Ä‘á»™ Ä‘á»“ng thuáº­n giá»¯a K-means vÃ  KNN
        agreement = sum(1 for k, n in zip(kmeans_pred, knn_pred) if k == n)
        agreement_rate = agreement / len(classified_students) if classified_students else 0
        
        return {
            'total_students': len(classified_students),
            'level_distribution': level_counts,
            'anomaly_count': anomaly_count,
            'anomaly_rate': anomaly_count / len(classified_students) if classified_students else 0,
            'kmeans_knn_agreement': agreement_rate
        }
    
    def cross_validate(self, students, n_folds=5):
        """Cross-validation Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ Ä‘á»™ á»•n Ä‘á»‹nh"""
        print(f"ğŸ”„ Äang cháº¡y {n_folds}-fold cross-validation...")
        
        # Chuáº©n bá»‹ dá»¯ liá»‡u
        n = len(students)
        fold_size = n // n_folds
        fold_results = []
        
        for fold in range(n_folds):
            # Chia train/test
            start_idx = fold * fold_size
            end_idx = start_idx + fold_size if fold < n_folds - 1 else n
            
            test_students = students[start_idx:end_idx]
            train_students = students[:start_idx] + students[end_idx:]
            
            # Train trÃªn train set
            classifier = StudentClassifier(n_clusters=4, normalization_method='minmax')
            classifier.fit(train_students)
            
            # Predict trÃªn test set
            test_classified = classifier.predict(test_students)
            
            # TÃ­nh metrics cho fold nÃ y
            metrics = self.calculate_metrics(test_classified)
            fold_results.append(metrics)
            
            print(f"   Fold {fold+1}: {metrics['level_distribution']}")
        
        # TÃ­nh trung bÃ¬nh
        avg_agreement = np.mean([r['kmeans_knn_agreement'] for r in fold_results])
        std_agreement = np.std([r['kmeans_knn_agreement'] for r in fold_results])
        
        print(f"   âœ… Cross-validation hoÃ n thÃ nh")
        print(f"   ğŸ“Š Äá»™ Ä‘á»“ng thuáº­n K-means/KNN: {avg_agreement:.2%} Â± {std_agreement:.2%}")
        
        return {
            'n_folds': n_folds,
            'fold_results': fold_results,
            'avg_agreement': avg_agreement,
            'std_agreement': std_agreement
        }
    
    def test_normalization_methods(self, students):
        """So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a"""
        print("ğŸ“ˆ So sÃ¡nh cÃ¡c phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a...")
        
        methods = ['minmax', 'zscore', 'robust']
        results = {}
        
        for method in methods:
            classified, _ = self.run_classification(students.copy(), method)
            metrics = self.calculate_metrics(classified)
            results[method] = metrics
            print(f"   {method.upper()}: {metrics['level_distribution']}")
        
        return results
    
    def analyze_anomalies(self, classified_students):
        """PhÃ¢n tÃ­ch chi tiáº¿t cÃ¡c trÆ°á»ng há»£p báº¥t thÆ°á»ng"""
        print("âš ï¸ PhÃ¢n tÃ­ch báº¥t thÆ°á»ng...")
        
        anomalies = [s for s in classified_students if s.get('anomaly_detected', False)]
        
        if not anomalies:
            print("   âœ… KhÃ´ng cÃ³ trÆ°á»ng há»£p báº¥t thÆ°á»ng")
            return {'count': 0, 'details': []}
        
        # PhÃ¢n loáº¡i theo severity
        severity_counts = {1: 0, 2: 0, 3: 0}
        reason_counts = {}
        
        details = []
        for s in anomalies:
            severity = s.get('anomaly_severity', 1)
            severity_counts[severity] = severity_counts.get(severity, 0) + 1
            
            reasons = s.get('anomaly_reasons', [])
            for reason in reasons:
                # Láº¥y loáº¡i lÃ½ do (pháº§n Ä‘áº§u)
                reason_type = reason.split('(')[0].strip() if '(' in reason else reason[:30]
                reason_counts[reason_type] = reason_counts.get(reason_type, 0) + 1
            
            details.append({
                'student_id': s.get('student_id'),
                'name': s.get('name'),
                'final_level': s.get('final_level'),
                'severity': severity,
                'reasons': reasons
            })
        
        print(f"   Tá»•ng sá»‘ báº¥t thÆ°á»ng: {len(anomalies)}")
        print(f"   Theo má»©c Ä‘á»™: Nháº¹={severity_counts.get(1,0)}, Trung bÃ¬nh={severity_counts.get(2,0)}, NghiÃªm trá»ng={severity_counts.get(3,0)}")
        print(f"   Top lÃ½ do:")
        for reason, count in sorted(reason_counts.items(), key=lambda x: -x[1])[:5]:
            print(f"      - {reason}: {count}")
        
        return {
            'count': len(anomalies),
            'severity_distribution': severity_counts,
            'reason_counts': reason_counts,
            'details': details[:10]  # Top 10
        }
    
    def validate_consistency(self, students):
        """Kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n cá»§a phÃ¢n loáº¡i"""
        print("ğŸ” Kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n...")
        
        # Cháº¡y phÃ¢n loáº¡i 3 láº§n vá»›i cÃ¹ng dá»¯ liá»‡u
        results = []
        for i in range(3):
            classified, _ = self.run_classification(students.copy(), 'minmax')
            levels = [s.get('final_level') for s in classified]
            results.append(levels)
        
        # So sÃ¡nh káº¿t quáº£
        consistent = 0
        for i in range(len(results[0])):
            if results[0][i] == results[1][i] == results[2][i]:
                consistent += 1
        
        consistency_rate = consistent / len(results[0]) if results[0] else 0
        print(f"   âœ… Tá»· lá»‡ nháº¥t quÃ¡n: {consistency_rate:.2%}")
        
        return {'consistency_rate': consistency_rate}
    
    def run_full_validation(self):
        """Cháº¡y toÃ n bá»™ quy trÃ¬nh validation"""
        print("=" * 70)
        print("ğŸ“ Há»† THá»NG KIá»‚M TRA Äá»˜ CHÃNH XÃC PHÃ‚N LOáº I SINH VIÃŠN")
        print("   Thuáº­t toÃ¡n: K-means + KNN + PhÃ¡t hiá»‡n báº¥t thÆ°á»ng")
        print("=" * 70)
        
        # 1. Load dá»¯ liá»‡u
        students = self.load_data()
        
        # 2. ÄÃ¡nh giÃ¡ ká»¹ nÄƒng
        students = self.evaluate_skills(students)
        
        # 3. PhÃ¢n loáº¡i chÃ­nh
        classified, classifier = self.run_classification(students)
        
        # 4. TÃ­nh metrics cÆ¡ báº£n
        print("\nğŸ“Š Káº¾T QUáº¢ PHÃ‚N LOáº I:")
        metrics = self.calculate_metrics(classified)
        self.results['basic_metrics'] = metrics
        
        print(f"   Tá»•ng sá»‘ sinh viÃªn: {metrics['total_students']}")
        print(f"   PhÃ¢n bá»‘:")
        for level, count in metrics['level_distribution'].items():
            pct = count / metrics['total_students'] * 100
            print(f"      - {level}: {count} ({pct:.1f}%)")
        print(f"   Báº¥t thÆ°á»ng: {metrics['anomaly_count']} ({metrics['anomaly_rate']:.1%})")
        print(f"   Äá»™ Ä‘á»“ng thuáº­n K-means/KNN: {metrics['kmeans_knn_agreement']:.1%}")
        
        # 5. Cross-validation
        print("\n" + "-" * 70)
        cv_results = self.cross_validate(students)
        self.results['cross_validation'] = cv_results
        
        # 6. So sÃ¡nh phÆ°Æ¡ng phÃ¡p chuáº©n hÃ³a
        print("\n" + "-" * 70)
        norm_results = self.test_normalization_methods(students)
        self.results['normalization_comparison'] = norm_results
        
        # 7. PhÃ¢n tÃ­ch báº¥t thÆ°á»ng
        print("\n" + "-" * 70)
        anomaly_analysis = self.analyze_anomalies(classified)
        self.results['anomaly_analysis'] = anomaly_analysis
        
        # 8. Kiá»ƒm tra tÃ­nh nháº¥t quÃ¡n
        print("\n" + "-" * 70)
        consistency = self.validate_consistency(students)
        self.results['consistency'] = consistency
        
        # 9. Tá»•ng káº¿t
        print("\n" + "=" * 70)
        print("ğŸ“‹ Tá»”NG Káº¾T VALIDATION")
        print("=" * 70)
        
        print(f"""
âœ… Káº¿t quáº£:
   - Tá»•ng sinh viÃªn: {metrics['total_students']}
   - Äá»™ Ä‘á»“ng thuáº­n K-means/KNN: {metrics['kmeans_knn_agreement']:.1%}
   - Cross-validation: {cv_results['avg_agreement']:.1%} Â± {cv_results['std_agreement']:.1%}
   - TÃ­nh nháº¥t quÃ¡n: {consistency['consistency_rate']:.1%}
   - Tá»· lá»‡ báº¥t thÆ°á»ng: {metrics['anomaly_rate']:.1%}

ğŸ“Š PhÃ¢n bá»‘ xáº¿p loáº¡i:
   - Xuáº¥t sáº¯c: {metrics['level_distribution'].get('Xuat sac', 0)}
   - KhÃ¡: {metrics['level_distribution'].get('Kha', 0)}
   - Trung bÃ¬nh: {metrics['level_distribution'].get('Trung binh', 0)}
   - Yáº¿u: {metrics['level_distribution'].get('Yeu', 0)}
        """)
        
        # 10. LÆ°u káº¿t quáº£
        self.save_results()
        
        return self.results
    
    def save_results(self):
        """LÆ°u káº¿t quáº£ validation ra file"""
        output_file = f'validation_results_{self.timestamp}.json'
        
        # Convert numpy types to Python types
        def convert(obj):
            if isinstance(obj, np.integer):
                return int(obj)
            elif isinstance(obj, np.floating):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, dict):
                return {k: convert(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [convert(i) for i in obj]
            return obj
        
        results_to_save = convert(self.results)
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results_to_save, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ÄÃ£ lÆ°u káº¿t quáº£ vÃ o: {output_file}")


def main():
    """Cháº¡y validation"""
    validator = ClassifierValidator()
    results = validator.run_full_validation()
    return results


if __name__ == "__main__":
    main()
