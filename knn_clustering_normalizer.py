"""
Module s·ª≠ d·ª•ng KNN ƒë·ªÉ ph√¢n c·ª•m v√† chu·∫©n h√≥a d·ªØ li·ªáu sinh vi√™n
H·ªó tr·ª£ nhi·ªÅu ph∆∞∆°ng ph√°p chu·∫©n h√≥a: Min-Max, Z-Score, Robust Scaler

KI·∫æN TR√öC: CH·ªà D√ôNG KNN (Kh√¥ng d√πng K-means)
=============================================
Module n√†y kh√°c v·ªõi student_classifier.py:
- student_classifier.py: D√πng K-MEANS + KNN (KNN h·ªó tr·ª£ K-means)
- Module n√†y: CH·ªà D√ôNG KNN (Supervised Learning thu·∫ßn t√∫y)

L√ù DO D√ôNG CH·ªà KNN:
===================
1. D·ªØ li·ªáu ƒë√£ c√≥ nh√£n s·∫µn (t·ª´ CSV: predicted_level)
2. Kh√¥ng c·∫ßn K-means ƒë·ªÉ t·∫°o nh√£n ban ƒë·∫ßu
3. KNN h·ªçc tr·ª±c ti·∫øp t·ª´ nh√£n c√≥ s·∫µn
4. T·∫≠p trung v√†o chu·∫©n h√≥a d·ªØ li·ªáu ƒë·ªÉ tƒÉng ƒë·ªô ch√≠nh x√°c

3 PH∆Ø∆†NG PH√ÅP CHU·∫®N H√ìA:
========================
1. MIN-MAX SCALING:
   - C√¥ng th·ª©c: (x - min) / (max - min)
   - K·∫øt qu·∫£: D·ªØ li·ªáu trong kho·∫£ng [0, 1]
   - ∆Øu ƒëi·ªÉm: ƒê∆°n gi·∫£n, gi·ªØ nguy√™n ph√¢n ph·ªëi
   - Nh∆∞·ª£c ƒëi·ªÉm: Nh·∫°y c·∫£m v·ªõi outliers

2. Z-SCORE (STANDARD SCALING):
   - C√¥ng th·ª©c: (x - mean) / std
   - K·∫øt qu·∫£: Mean = 0, Std = 1
   - ∆Øu ƒëi·ªÉm: Ph√π h·ª£p v·ªõi ph√¢n ph·ªëi chu·∫©n
   - Nh∆∞·ª£c ƒëi·ªÉm: Nh·∫°y c·∫£m v·ªõi outliers

3. ROBUST SCALING:
   - C√¥ng th·ª©c: (x - median) / IQR
   - K·∫øt qu·∫£: Median = 0, IQR = 1
   - ∆Øu ƒëi·ªÉm: Ch·ªëng nhi·ªÖu t·ªët, d√πng median thay v√¨ mean
   - Nh∆∞·ª£c ƒëi·ªÉm: Ph·ª©c t·∫°p h∆°n

KNN PH√ÇN LO·∫†I SINH VI√äN:
========================
- ƒê·∫ßu v√†o: 13 ƒë·∫∑c tr∆∞ng (ƒëi·ªÉm s·ªë, th·ªùi gian, h√†nh vi)
- ƒê·∫ßu ra: 4 m·ª©c ƒë·ªô (Xu·∫•t s·∫Øc, Kh√°, Trung b√¨nh, Y·∫øu)
- Ph∆∞∆°ng ph√°p: T√¨m k l√°ng gi·ªÅng g·∫ßn nh·∫•t v√† vote
"""

import numpy as np
from sklearn.neighbors import KNeighborsClassifier  # NOTE: CH·ªà D√ôNG KNN - Kh√¥ng d√πng K-means
from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler  # NOTE: 3 ph∆∞∆°ng ph√°p chu·∫©n h√≥a
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.metrics import classification_report, confusion_matrix
import warnings
warnings.filterwarnings('ignore')


class KNNClusteringNormalizer:
    """
    L·ªõp ph√¢n c·ª•m sinh vi√™n s·ª≠ d·ª•ng KNN v·ªõi nhi·ªÅu ph∆∞∆°ng ph√°p chu·∫©n h√≥a
    """
    
    def __init__(self, n_neighbors=5, normalization_method='minmax'):
        """
        Kh·ªüi t·∫°o KNN Clustering v·ªõi ph∆∞∆°ng ph√°p chu·∫©n h√≥a
        
        NOTE: CH·ªà D√ôNG KNN - Kh√¥ng d√πng K-means
        ========================================
        Module n√†y kh√°c v·ªõi StudentClassifier:
        - StudentClassifier: K-means (t·∫°o nh√£n) + KNN (h·ªçc t·ª´ nh√£n)
        - Module n√†y: CH·ªà KNN (h·ªçc t·ª´ nh√£n c√≥ s·∫µn trong CSV)
        
        Args:
            n_neighbors: S·ªë l∆∞·ª£ng l√°ng gi·ªÅng cho KNN (m·∫∑c ƒë·ªãnh 5)
            normalization_method: Ph∆∞∆°ng ph√°p chu·∫©n h√≥a ('minmax', 'zscore', 'robust')
        """
        self.n_neighbors = n_neighbors
        self.normalization_method = normalization_method
        
        # NOTE: Scaler - Chu·∫©n h√≥a d·ªØ li·ªáu
        # Ch·ªçn 1 trong 3: MinMaxScaler, StandardScaler, RobustScaler
        self.scaler = self._get_scaler()
        
        # NOTE: CH·ªà D√ôNG KNN - Kh√¥ng c√≥ K-means
        self.knn = None
        
        self.feature_names = []
        
        # NOTE: Mapping nh√£n text -> s·ªë ƒë·ªÉ KNN c√≥ th·ªÉ h·ªçc
        self.label_mapping = {
            "Xuat sac": 3,
            "Kha": 2,
            "Trung binh": 1,
            "Yeu": 0
        }
        self.reverse_label_mapping = {v: k for k, v in self.label_mapping.items()}
    
    def _get_scaler(self):
        """
        L·∫•y scaler d·ª±a tr√™n ph∆∞∆°ng ph√°p chu·∫©n h√≥a
        
        NOTE: 3 PH∆Ø∆†NG PH√ÅP CHU·∫®N H√ìA
        ==============================
        1. MIN-MAX: Chu·∫©n h√≥a v·ªÅ [0, 1]
           - C√¥ng th·ª©c: (x - min) / (max - min)
           - D√πng khi: D·ªØ li·ªáu kh√¥ng c√≥ outliers
        
        2. Z-SCORE: Chu·∫©n h√≥a theo ph√¢n ph·ªëi chu·∫©n
           - C√¥ng th·ª©c: (x - mean) / std
           - D√πng khi: D·ªØ li·ªáu c√≥ ph√¢n ph·ªëi chu·∫©n
        
        3. ROBUST: Chu·∫©n h√≥a ch·ªëng nhi·ªÖu
           - C√¥ng th·ª©c: (x - median) / IQR
           - D√πng khi: D·ªØ li·ªáu c√≥ nhi·ªÅu outliers
        """
        if self.normalization_method == 'minmax':
            # NOTE: MIN-MAX SCALER - Chu·∫©n h√≥a v·ªÅ [0, 1]
            return MinMaxScaler()
        elif self.normalization_method == 'zscore':
            # NOTE: STANDARD SCALER (Z-Score) - Chu·∫©n h√≥a theo ph√¢n ph·ªëi chu·∫©n
            return StandardScaler()
        elif self.normalization_method == 'robust':
            # NOTE: ROBUST SCALER - Chu·∫©n h√≥a ch·ªëng nhi·ªÖu
            return RobustScaler()
        else:
            raise ValueError(f"Ph∆∞∆°ng ph√°p chu·∫©n h√≥a kh√¥ng h·ª£p l·ªá: {self.normalization_method}")
    
    def extract_features(self, students):
        """
        Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu sinh vi√™n
        
        Args:
            students: Danh s√°ch sinh vi√™n
            
        Returns:
            numpy array c√°c ƒë·∫∑c tr∆∞ng
        """
        features = []
        self.feature_names = [
            'avg_score', 'avg_time', 'score_std', 'time_std',
            'midterm', 'final', 'homework', 'attendance',
            'assignment_completion', 'study_hours', 'lms_usage',
            'behavior_score', 'num_passed'
        ]
        
        for student in students:
            csv_data = student.get("csv_data", {})
            
            if csv_data:
                # L·∫•y d·ªØ li·ªáu t·ª´ CSV
                midterm = float(csv_data.get("midterm_score", 0))
                final = float(csv_data.get("final_score", 0))
                homework = float(csv_data.get("homework_score", 0))
                attendance = float(csv_data.get("attendance_rate", 0))
                assignment = float(csv_data.get("assignment_completion", 0))
                study_hours = float(csv_data.get("study_hours", 0))
                lms_usage = float(csv_data.get("lms_usage", 0))
                behavior = float(csv_data.get("behavior_score", 0))
                
                # T√≠nh ƒëi·ªÉm trung b√¨nh
                course_scores = [midterm, final, homework]
                avg_score = np.mean(course_scores)
                score_std = np.std(course_scores)
                
                # Th·ªùi gian h·ªçc
                avg_time = study_hours * 60 / 4  # Chia cho 4 m√¥n
                time_std = study_hours * 10  # Gi·∫£ ƒë·ªãnh ƒë·ªô l·ªách
                
                # S·ªë m√¥n ƒë·∫°t
                num_passed = sum(1 for s in course_scores if s >= 5.5)
                
            else:
                # Fallback: t√≠nh t·ª´ d·ªØ li·ªáu courses
                course_scores = []
                course_times = []
                
                for course_name in ["Nh·∫≠p M√¥n L·∫≠p Tr√¨nh", "Kƒ© Thu·∫≠t L·∫≠p Tr√¨nh",
                                   "C·∫•u tr√∫c D·ªØ Li·ªáu v√† Gi·∫£i Thu·∫≠t", "L·∫≠p Tr√¨nh H∆∞·ªõng ƒê·ªëi T∆∞·ª£ng"]:
                    if course_name in student.get("courses", {}):
                        course_data = student["courses"][course_name]
                        course_scores.append(course_data.get("score", 0))
                        course_times.append(course_data.get("time_minutes", 0))
                
                avg_score = np.mean(course_scores) if course_scores else 0
                score_std = np.std(course_scores) if course_scores else 0
                avg_time = np.mean(course_times) if course_times else 0
                time_std = np.std(course_times) if course_times else 0
                
                # Gi√° tr·ªã m·∫∑c ƒë·ªãnh
                midterm = avg_score
                final = avg_score
                homework = avg_score
                attendance = 0.8
                assignment = 0.8
                study_hours = avg_time / 15
                lms_usage = study_hours * 0.5
                behavior = 80
                
                num_passed = sum(1 for s in course_scores if s >= 5.5)
            
            feature_vector = [
                avg_score, avg_time, score_std, time_std,
                midterm, final, homework, attendance,
                assignment, study_hours, lms_usage,
                behavior, num_passed
            ]
            
            features.append(feature_vector)
        
        return np.array(features)

    def normalize_features(self, features, fit=True):
        """
        Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng
        
        Args:
            features: M·∫£ng ƒë·∫∑c tr∆∞ng
            fit: True n·∫øu c·∫ßn fit scaler, False n·∫øu ch·ªâ transform
            
        Returns:
            M·∫£ng ƒë√£ chu·∫©n h√≥a
        """
        if fit:
            return self.scaler.fit_transform(features)
        else:
            return self.scaler.transform(features)
    
    def get_labels(self, students):
        """
        L·∫•y nh√£n t·ª´ d·ªØ li·ªáu sinh vi√™n
        
        Args:
            students: Danh s√°ch sinh vi√™n
            
        Returns:
            M·∫£ng nh√£n s·ªë
        """
        labels = []
        for student in students:
            # ∆Øu ti√™n l·∫•y t·ª´ CSV
            csv_data = student.get("csv_data", {})
            if csv_data and "predicted_level" in csv_data:
                level = csv_data["predicted_level"]
                # Chu·∫©n h√≥a t√™n level
                level = level.replace("Xu·∫•t s·∫Øc", "Xuat sac").replace("Y·∫øu", "Yeu")
            else:
                level = student.get("base_level", "Trung binh")
            
            labels.append(self.label_mapping.get(level, 1))
        
        return np.array(labels)
    
    def fit(self, students):
        """
        Hu·∫•n luy·ªán m√¥ h√¨nh KNN
        
        NOTE: QUY TR√åNH HU·∫§N LUY·ªÜN CH·ªà D√ôNG KNN
        ========================================
        1. Tr√≠ch xu·∫•t 13 ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu sinh vi√™n
        2. Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng (minmax/zscore/robust)
        3. L·∫•y nh√£n t·ª´ CSV (predicted_level)
        4. Hu·∫•n luy·ªán KNN v·ªõi nh√£n c√≥ s·∫µn
        
        KH√ÅC BI·ªÜT V·ªöI student_classifier.py:
        - student_classifier.py: K-means t·∫°o nh√£n -> KNN h·ªçc t·ª´ nh√£n ƒë√≥
        - Module n√†y: Nh√£n c√≥ s·∫µn trong CSV -> KNN h·ªçc tr·ª±c ti·∫øp
        
        Args:
            students: Danh s√°ch sinh vi√™n ƒë·ªÉ hu·∫•n luy·ªán
        """
        # NOTE: B∆Ø·ªöC 1 - Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng
        # 13 ƒë·∫∑c tr∆∞ng: ƒëi·ªÉm s·ªë, th·ªùi gian, h√†nh vi, tham gia...
        features = self.extract_features(students)
        
        # NOTE: B∆Ø·ªöC 2 - Chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng
        # S·ª≠ d·ª•ng 1 trong 3 ph∆∞∆°ng ph√°p: minmax, zscore, robust
        # M·ª•c ƒë√≠ch: ƒê∆∞a c√°c ƒë·∫∑c tr∆∞ng v·ªÅ c√πng thang ƒëo
        features_normalized = self.normalize_features(features, fit=True)
        
        # NOTE: B∆Ø·ªöC 3 - L·∫•y nh√£n t·ª´ CSV
        # Nh√£n ƒë√£ c√≥ s·∫µn trong d·ªØ li·ªáu (predicted_level)
        # Kh√¥ng c·∫ßn K-means ƒë·ªÉ t·∫°o nh√£n
        labels = self.get_labels(students)
        
        # NOTE: B∆Ø·ªöC 4 - ƒêi·ªÅu ch·ªânh k cho KNN
        # k = s·ªë l√°ng gi·ªÅng g·∫ßn nh·∫•t ƒë·ªÉ xem x√©t
        # k nh·ªè: Nh·∫°y c·∫£m v·ªõi nhi·ªÖu
        # k l·ªõn: M∆∞·ª£t h∆°n nh∆∞ng m·∫•t chi ti·∫øt
        k = min(self.n_neighbors, len(students) // 2)
        k = max(1, k)
        
        # NOTE: B∆Ø·ªöC 5 - Hu·∫•n luy·ªán KNN
        # weights='distance': L√°ng gi·ªÅng g·∫ßn c√≥ tr·ªçng s·ªë cao h∆°n
        self.knn = KNeighborsClassifier(n_neighbors=k, weights='distance')
        self.knn.fit(features_normalized, labels)
        
        print(f"‚úÖ ƒê√£ hu·∫•n luy·ªán KNN v·ªõi k={k}, ph∆∞∆°ng ph√°p chu·∫©n h√≥a: {self.normalization_method}")
    
    def predict(self, students):
        """
        D·ª± ƒëo√°n ph√¢n lo·∫°i cho sinh vi√™n
        
        Args:
            students: Danh s√°ch sinh vi√™n c·∫ßn ph√¢n lo·∫°i
            
        Returns:
            Danh s√°ch sinh vi√™n k√®m k·∫øt qu·∫£ ph√¢n lo·∫°i
        """
        if self.knn is None:
            raise ValueError("M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. G·ªçi fit() tr∆∞·ªõc.")
        
        # Tr√≠ch xu·∫•t v√† chu·∫©n h√≥a ƒë·∫∑c tr∆∞ng
        features = self.extract_features(students)
        features_normalized = self.normalize_features(features, fit=False)
        
        # D·ª± ƒëo√°n
        predictions = self.knn.predict(features_normalized)
        probabilities = self.knn.predict_proba(features_normalized)
        
        # L·∫•y c√°c classes m√† KNN ƒë√£ h·ªçc
        classes = self.knn.classes_
        
        # T·∫°o k·∫øt qu·∫£
        results = []
        for i, student in enumerate(students):
            predicted_label = self.reverse_label_mapping[predictions[i]]
            
            # T√¨m index c·ªßa prediction trong classes
            pred_idx = np.where(classes == predictions[i])[0][0]
            confidence = probabilities[i][pred_idx]
            
            # T·∫°o dict probabilities v·ªõi ƒë√∫ng classes
            prob_dict = {}
            for j, class_label in enumerate(classes):
                level_name = self.reverse_label_mapping[class_label]
                prob_dict[level_name] = float(probabilities[i][j])
            
            result = {
                **student,
                "knn_prediction": predicted_label,
                "confidence": float(confidence),
                "probabilities": prob_dict
            }
            results.append(result)
        
        return results
    
    def evaluate(self, students):
        """
        ƒê√°nh gi√° m√¥ h√¨nh v·ªõi cross-validation
        
        Args:
            students: Danh s√°ch sinh vi√™n ƒë·ªÉ ƒë√°nh gi√°
            
        Returns:
            Dictionary ch·ª©a c√°c metrics ƒë√°nh gi√°
        """
        features = self.extract_features(students)
        features_normalized = self.normalize_features(features, fit=True)
        labels = self.get_labels(students)
        
        # Cross-validation
        cv_scores = cross_val_score(self.knn, features_normalized, labels, cv=5)
        
        # Train-test split ƒë·ªÉ c√≥ confusion matrix
        X_train, X_test, y_train, y_test = train_test_split(
            features_normalized, labels, test_size=0.2, random_state=42, stratify=labels
        )
        
        self.knn.fit(X_train, y_train)
        y_pred = self.knn.predict(X_test)
        
        # L·∫•y c√°c labels th·ª±c s·ª± c√≥ trong y_test
        unique_labels = sorted(set(y_test) | set(y_pred))
        target_names = [self.reverse_label_mapping[label] for label in unique_labels]
        
        # Classification report
        report = classification_report(
            y_test, y_pred,
            labels=unique_labels,
            target_names=target_names,
            output_dict=True,
            zero_division=0
        )
        
        # Confusion matrix
        cm = confusion_matrix(y_test, y_pred, labels=unique_labels)
        
        return {
            "cv_scores": cv_scores.tolist(),
            "cv_mean": float(cv_scores.mean()),
            "cv_std": float(cv_scores.std()),
            "classification_report": report,
            "confusion_matrix": cm.tolist(),
            "labels": target_names
        }
    
    def get_feature_importance(self, students):
        """
        T√≠nh ƒë·ªô quan tr·ªçng c·ªßa c√°c ƒë·∫∑c tr∆∞ng (d·ª±a tr√™n ph∆∞∆°ng sai)
        
        Args:
            students: Danh s√°ch sinh vi√™n
            
        Returns:
            Dictionary mapping t√™n ƒë·∫∑c tr∆∞ng -> ƒë·ªô quan tr·ªçng
        """
        features = self.extract_features(students)
        features_normalized = self.normalize_features(features, fit=True)
        
        # T√≠nh ph∆∞∆°ng sai c·ªßa m·ªói ƒë·∫∑c tr∆∞ng
        variances = np.var(features_normalized, axis=0)
        
        # Chu·∫©n h√≥a v·ªÅ t·ªïng = 1
        total_var = np.sum(variances)
        importances = variances / total_var if total_var > 0 else variances
        
        return {
            name: float(imp)
            for name, imp in zip(self.feature_names, importances)
        }


def compare_normalization_methods(students):
    """
    So s√°nh c√°c ph∆∞∆°ng ph√°p chu·∫©n h√≥a kh√°c nhau
    
    Args:
        students: Danh s√°ch sinh vi√™n
        
    Returns:
        Dictionary ch·ª©a k·∫øt qu·∫£ so s√°nh
    """
    methods = ['minmax', 'zscore', 'robust']
    results = {}
    
    for method in methods:
        print(f"\nüìä ƒê√°nh gi√° ph∆∞∆°ng ph√°p: {method.upper()}")
        classifier = KNNClusteringNormalizer(n_neighbors=5, normalization_method=method)
        classifier.fit(students)
        
        evaluation = classifier.evaluate(students)
        results[method] = {
            "cv_mean": evaluation["cv_mean"],
            "cv_std": evaluation["cv_std"],
            "classification_report": evaluation["classification_report"]
        }
        
        print(f"  ‚úì ƒê·ªô ch√≠nh x√°c trung b√¨nh: {evaluation['cv_mean']:.4f} (¬±{evaluation['cv_std']:.4f})")
    
    return results
